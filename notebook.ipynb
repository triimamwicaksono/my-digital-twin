{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "025d9854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/triimamwicaksono/Document/Mini Project/my-digital-twin/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from dotenv import load_dotenv\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cbe3cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import langchain\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, TextLoader,PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables import ConfigurableFieldSpec\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baf87472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_docs(data_dir: str) -> list:\n",
    "    \"\"\"\n",
    "    Load all PDF and MD files from a folder into LangChain Documents.\n",
    "    Returns a list of Documents with basic metadata.\n",
    "    \"\"\"\n",
    "    documents = []\n",
    "\n",
    "    for file in os.listdir(data_dir):\n",
    "        if file.endswith(\".pdf\"):\n",
    "            loader = PyMuPDFLoader(os.path.join(data_dir, file))\n",
    "            documents.extend(loader.load())\n",
    "        elif file.endswith(\".md\"):\n",
    "            loader = TextLoader(os.path.join(data_dir, file), encoding='utf-8')\n",
    "            documents.extend(loader.load())\n",
    "\n",
    "    return documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469f65d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_docs(docs:list) -> list:\n",
    "    \"\"\"Chunk documents into smaller pieces.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap=200)\n",
    "    return text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "164ab164",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = load_docs(\"./knowledge-base\")\n",
    "chunks = chunk_docs(docs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c48c55fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 10\n",
      "First chunk:\n",
      " Senior Data Analyst with 6+ years of experience in product experimentation, behavioral analytics, and\n",
      "KPI optimization to drive product-led growth. Proven track record in shaping roadmap decisions\n",
      "through statistically sound A/B testing, funnel analysis, and LTV/retention modeling. Highly skilled in\n",
      "building scalable data pipelines and real-time dashboards that influence executive and cross-\n",
      "functional decisions. Currently pursuing a Master’s in Business Information Technology (specializing in\n",
      "D\n"
     ]
    }
   ],
   "source": [
    "print(\"Total chunks:\", len(chunks))\n",
    "print(\"First chunk:\\n\", chunks[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b029319e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6x/tjtz85yd37n5sb4nwqmv5wc40000gn/T/ipykernel_89960/3185160268.py:10: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
      "/var/folders/6x/tjtz85yd37n5sb4nwqmv5wc40000gn/T/ipykernel_89960/3185160268.py:16: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vectordb.persist()\n"
     ]
    }
   ],
   "source": [
    "db_name = \"chroma-db\"\n",
    "\n",
    "# Ensure environment variables are loaded\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "\traise ValueError(\"OPENAI_API_KEY environment variable not found. Please set it in your .env file.\")\n",
    "\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "\n",
    "if not os.path.exists(db_name):\n",
    "    os.makedirs(db_name)\n",
    "    vectordb = Chroma.from_documents(documents=chunks, embedding=embeddings, persist_directory=db_name)\n",
    "\n",
    "    vectordb.persist()\n",
    "else:\n",
    "    vectordb = Chroma(persist_directory=db_name, embedding_function=embeddings)\n",
    "    vectordb.persist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "522b1346",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7, model = \"gpt-4o\")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\",\n",
    "        \"You are Tri's representative. Answer ONLY from the provided context. \"\n",
    "        \"If you don't know, say \\\"I don't know\\\" and ask the user to clarify. \"\n",
    "        \"Keep answers to 2–4 sentences. Reply in the same language as the question.\"\n",
    "        \"Context:\\n{context}\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"Question:{input}\")])\n",
    "\n",
    "\n",
    "documents_chain = create_stuff_documents_chain(llm,prompt)\n",
    "\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 15})\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever, documents_chain)\n",
    "retrieval_chain = retrieval_chain | RunnableLambda(lambda x: x[\"answer\"]) | StrOutputParser()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8d854680",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(user_id: str, conversation_id: str) -> ChatMessageHistory:\n",
    "    if (user_id, conversation_id) not in store:\n",
    "        store[(user_id, conversation_id)] = ChatMessageHistory()\n",
    "    return store[(user_id, conversation_id)]\n",
    "\n",
    "\n",
    "chain_with_history = RunnableWithMessageHistory(retrieval_chain,\n",
    "                                                history_messages_key=\"history\",\n",
    "                                                input_messages_key=\"input\",\n",
    "                                                get_session_history=get_session_history,\n",
    "                                                history_factory_config=[\n",
    "                                                ConfigurableFieldSpec(\n",
    "                                                    id=\"user_id\",\n",
    "                                                    annotation=str,\n",
    "                                                    name=\"User ID\",\n",
    "                                                    description=\"Unique identifier for the user.\",\n",
    "                                                    default=\"\",\n",
    "                                                    is_shared=True,\n",
    "                                                ),\n",
    "                                                ConfigurableFieldSpec(\n",
    "                                                    id=\"conversation_id\",\n",
    "                                                    annotation=str,\n",
    "                                                    name=\"Conversation ID\",\n",
    "                                                    description=\"Unique identifier for the conversation.\",\n",
    "                                                    default=\"\",\n",
    "                                                    is_shared=True,\n",
    "                                                ),\n",
    "                                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ba221d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At Tokopedia, Tri worked as a Senior Data Analyst from 2018 to 2022. He partnered with Product Managers, Engineers, and Designers to drive experimentation and product optimization at scale. He designed and executed over 50 A/B tests, which led to a 10% uplift in checkout conversion rates, and reduced time-to-insight by automating experimentation reporting and metric monitoring. Tri also built SQL pipelines and maintained dashboards to improve data-driven decision-making across the platform.\n"
     ]
    }
   ],
   "source": [
    "cfg = {\"configurable\": {\"user_id\": \"u1\", \"conversation_id\": \"c1\"}}\n",
    "result = chain_with_history.invoke({\"input\": \"What did Tri do at Tokopedia?\"}, config=cfg)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f57ab65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_config(session_hash:str):\n",
    "    return {\"configurable\": {\"user_id\": session_hash, \"conversation_id\": session_hash}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef24931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(message, history, session_id):\n",
    "    cfg = {\"configurable\": {\"user_id\": session_id, \"conversation_id\": session_id}}\n",
    "\n",
    "    partial = \"\"\n",
    "    for chunk in chain_with_history.stream({\"input\": message}, config=cfg):\n",
    "        if isinstance(chunk, dict):\n",
    "            text = chunk.get(\"answer\", \"\")\n",
    "        else:\n",
    "            text = getattr(chunk, \"content\", str(chunk))\n",
    "\n",
    "        partial += text\n",
    "        yield partial   # just the assistant message being built\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c70fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7874\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import gradio as gr\n",
    "\n",
    "def slow_echo(message, history):\n",
    "    for i in range(len(message)):\n",
    "        time.sleep(0.3)  # simulate delay\n",
    "        yield \"You typed: \" + message[: i+1]   # stream partial output\n",
    "\n",
    "gr.ChatInterface(\n",
    "    fn=slow_echo, \n",
    "    type=\"messages\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525ef4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
